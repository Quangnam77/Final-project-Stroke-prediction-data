# -*- coding: utf-8 -*-
"""final project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15qdgBq6xybNLwLpn5jCzPv3ir6ABx-Zw

# 1.Import neccessary libraries
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import statsmodels.api as sm

"""# 2.ETL data from Kaggle"""

df = pd.read_csv('/content/drive/MyDrive/Final Project Da/healthcare-dataset-stroke-data.csv')

"""## 2.1. Check information data and describe"""

df.head()

df.info()
df.describe()

"""Based on the stroke data, this data contain 5110 values with total 12 columns on the database with 3 dtypes: float64, int64, and object.

# 2.2.Check how many this data have null value
"""

df.isnull().sum()

"""According to the sumary result, in Bmi column, it only have 4909 values that means it has a null value to execute and replace.

# 2.3. Replace null value in bmi
"""

bmi_mean = df['bmi'].mean()
df['bmi'].fillna(bmi_mean, inplace=True)
df.isnull().sum()

"""# 2.4. Drop duplicate values in database"""

df.drop_duplicates(inplace=True)
df.info()

"""# 3. General EDA for database

# 3.1. Check the distribution of numeric column in the database
"""

sns.pairplot(df, hue='stroke')

num_cols = ["age","avg_glucose_level","bmi"]
df[num_cols].hist(figsize=(20,20), bins=30)
plt.suptitle("Numeric Distributions")
plt.show()

"""Data values were distributed normally

# 4.Create suitable group for some columns
"""

df['smoke_group'] = df['smoking_status'].map(
    lambda x: 'smoking' if x in ['smokes', 'formerly_smoked'] else 'non_smoke')

def bmi_category(a):
    if a <= 18.5:
        return "Underweight"
    elif 18.5 <= a <= 24.9:
        return 'Normal'
    elif 24.9 <= a <= 29.9:
        return 'Overweight'
    else:
        return 'Obese'

df['bmi'] = df['bmi'].apply(bmi_category)

def glucose_category(b):
    if 0<= b <= 70:
        return "Low"
    elif 70 <= b <= 100:
        return 'Normal'
    elif 100 <= b <= 126:
        return 'Prediabetes'
    else:
        return 'Diabetes'

df['avg_glucose_level'] = df['avg_glucose_level'].apply(glucose_category)

def age_category(c):
    if 0<= c <= 17:
        return "young"
    elif 18 <= c <= 24:
        return 'teenager'
    elif 25 <= c <= 64:
        return 'aldult'
    else:
        return 'old'

df['age'] = df['age'].apply(age_category)

"""# 4.1.Convert categorical data to numeric"""

df_encoded = pd.get_dummies(df, columns=['gender', 'smoke_group', 'ever_married','Residence_type','work_type','bmi','avg_glucose_level','age'])
print(df_encoded)

"""# 4.2.Drop unecessary column to make the data simple and easy to analys"""

drop_columns = ['gender_Female', 'gender_Other','smoking_status']
df_encoded.drop(columns=['id']+ drop_columns, inplace=True)
df_encoded.info()

"""# 4.3. Change suitable type for data"""

exclude_cols= ['hypertension','heart_disease']
df_encoded = df_encoded.apply(lambda x: x.astype(int) if x.name not in exclude_cols else x)
df_encoded.info()

print(df_encoded)

"""# 5. General Analysis data

"""

correlation_matrix = df_encoded.corr()
correlation_matrix
plt.figure(figsize=(30,30))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

"""Heatmap represent the relationship of each values in the datamodels. We can see Stroke have protpotional to old, diabetes, overweight, smoking, hypertension and heart disease. That means this type affect and can lead to stroke easily.

Built Regression model
"""

y_cols = ['stroke']
x = df_encoded.drop(columns=y_cols)
y = df_encoded['stroke']
x = sm.add_constant(x)
model= sm.OLS(y,x).fit()
print(model.summary())

"""In Linear regression, we can see in gender Male have the P-value > 0.05 so that gender Male need to drop out the database"""

y_cols = ['stroke', 'gender_Male']
x = df_encoded.drop(columns=y_cols)
y = df_encoded['stroke']
x = sm.add_constant(x)
model= sm.OLS(y,x).fit()
print(model.summary())

df_encoded.to_csv("final_project_output.csv", index=False, encoding="utf-8")
df.to_csv("stroke_predict.csv", index=False, encoding="utf-8")

"""Random forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

x = df_encoded.drop(columns=['stroke'])
y = df_encoded['stroke']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
x_train = sm.add_constant(x_train)
x_test = sm.add_constant(x_test)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(x_train, y_train)
mode = model.predict(x_test)
accuracy = accuracy_score(y_test, mode)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, mode))